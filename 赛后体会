这里简单的谈一下这次比赛之后的体会以及走过的坑，防止以后再踩同样的坑，同时借鉴学习一下前排队伍采取的方案。

心得体会

1、从小模型入手
一开始我们就选择复现了别人的论文，一个将近30层的resnet作为backbone，然后在这个基础上修改。好处在于这个深层的网络确实每一次训练都能获得接近NMSE0.1的效果，总会给人以希望。
坏处就在于每一次训练所需要的时间太久，我们想到的一些数据处理的trick尝试一次都要花费接近半天的时间。而这些trick不一定有效，有些甚至有反作用，这些都需要尝试才知道，但是大网络
的尝试成本太高了。所以，我们的第一个心得体会就是要从小模型入手，在小模型上尝试各种不同的trick，看看trick的效果然后再加大加深模型。

2、不要迷恋最新的网络和花哨的技术
这一点其实很容易就上当了，几乎每一个月都会有新鲜的网络架构或者组件诞生，每一个新技术都宣称自己是SOTA。这里不谈这些技术的普适性和实用性，只是单纯的从解决无线通信问题的角度出发的话，很多
的技术都过于花哨了，或者说杀鸡用牛刀，反而会获得相反的效果。不如采取相当成熟的网络架构作为backbone,然后再修改。

3、微调是最后的手段
其实这次比赛大多数时间我们并不是在做trick的尝试，而是在微调。而实际上，我们可能需要想象一下微调能达到的性能提升之后再考虑做不做微调。例如，我们没有微调时NMSE=0.12，那么根据这个问题的难度
通过微调使得NMSE=0.1并不现实（大量尝试下得到的结论）。但我们还是一直在做微调，甚至有些尝试还在走回头路，这就浪费了大量时间思考和尝试trick。

4、版本管理
这也是加快工作进程的必要方法之一，有了版本管理其实能够少走很多回头路以及弯路，有一些版本和结果能够直接拿来分析和对比。但我们这次懒得写版本管理文档，使得最后其实做了很多已经做过的工作。


观看其他队伍方案后的感想：

1、TOP-k路径保留思路
这个思路其实我们一开始就想到了，因为从通信的角度来讲，一共24条路径要做有损的信道信息压缩的话，肯定是根据功率大小给每一条路径排序，然后只取前top-k 个路径做压缩，其他的舍弃。
这其实是一个做通信问题的思路，而不是正常的从CV或者NLP视角看待问题的方式。而这个方案的难点在于如何将保存下来的路径位置信息记录下来并交给decoder还原，也就是说，有一部分bit用来
专门保存那些top-k路径的位置信息，然后decoder这里能够通过这些bit找到这些路径的对应位置。而那些被舍弃掉的路径就直接所有的值硬判决为0.5,即均值。

2、非均匀量化问题
这个问题其实我们也想到了，只不过没有想到如何实现。其实这是一个很自然而然就能想到的方案，如果每一个元素都被B bit均匀量化，那么有些接近0 或者接近 1的元素就会导致较大的误差，而接近0.5的元素又不需要 B bit
来进行量化，就造成了浪费。如何给不同的元素分配不同的量化bit成了一个问题。这里贴出第一名队伍的思路，即根据TOP-K路径的排序，给这TOP-K路径上的元素分配不同的bit数，即功率越大的路径，分配得到的bit数就越多。

3、向量量化
这个其实我目前还不是很理解第一名的队伍是如何把这个技术用到这个问题中的，不过按路径域做向量量化确实会比按元素做标量量化来得要更加合理且简洁。
